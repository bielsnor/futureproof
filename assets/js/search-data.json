{
  
    
        "post0": {
            "title": "Hospitalizations by State",
            "content": "# Imports import os import pandas as pd import csv import kaggle # other imports import numpy as np import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split from sklearn.model_selection import GridSearchCV from sklearn.linear_model import ElasticNet from sklearn.linear_model import LinearRegression from sklearn.preprocessing import PolynomialFeatures from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report from sklearn.utils.testing import ignore_warnings from sklearn.exceptions import ConvergenceWarning from copy import copy import seaborn as sns from scipy.stats import norm import matplotlib.dates as mdates # import matplotlib.colors as mcolors # import random # import math # import time # from sklearn.linear_model import LinearRegression, BayesianRidge # from sklearn.model_selection import RandomizedSearchCV from sklearn.tree import DecisionTreeRegressor # from sklearn.svm import SVR from datetime import date, datetime from dateutil.parser import parse import us # import operator # plt.style.use(&#39;fivethirtyeight&#39;) import plotly.graph_objects as go from plotly.subplots import make_subplots %matplotlib inline . c: programdata anaconda3 lib site-packages sklearn utils deprecation.py:144: FutureWarning: The sklearn.utils.testing module is deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API. warnings.warn(message, FutureWarning) . Covid Tracking Dataset (w/ hospitalised data) . Source: https://covidtracking.com/ . Step 1: Load and Clean the Data . all_cases = pd.read_csv(&#39;https://covidtracking.com/api/v1/states/daily.csv&#39;) # Delete unecessary rows for row in [&#39;negative&#39;, &#39;pending&#39;, &#39;hash&#39;, &#39;negativeIncrease&#39;, &#39;totalTestResults&#39;, &#39;totalTestResultsIncrease&#39;, &#39;dateChecked&#39;, &#39;fips&#39;, &#39;inIcuCumulative&#39;, &#39;onVentilatorCumulative&#39;, &#39;total&#39;, &#39;posNeg&#39;, &#39;deathIncrease&#39;, &#39;hospitalizedIncrease&#39;, &#39;positiveIncrease&#39;]: del all_cases[row] # TODO missing values # Do we get avg or missing values, or predict them? # See https://developerzen.com/data-mining-handling-missing-values-the-database-bd2241882e72 for i, row in all_cases.iterrows(): # Set Dates s = str(row[&#39;date&#39;]) all_cases.at[i, &#39;date&#39;] = date(year=int(s[0:4]), month=int(s[4:6]), day=int(s[6:8])) # Missing death figures means no death reports yet # These are set to 0 for i, row in all_cases.iterrows(): if np.isnan(row[&#39;death&#39;]): all_cases.at[i, &#39;death&#39;] = 0 . Missing values: Retrieving from other datasets or through merging columns (or both) . The following will be done: . Active Cases: Retrieved from JHU dataset and calculating $active = pos-dead-recovered$ | Beds per State: Retrieved from External Datasets | . # TODO Replace active cases with JHU and/or regression model (Selma) all_cases[&#39;active&#39;] = all_cases[&#39;positive&#39;] - all_cases[&#39;recovered&#39;] - all_cases[&#39;death&#39;] # change location of &#39;active&#39; column cols = list(all_cases) cols.insert(3, cols.pop(cols.index(&#39;active&#39;))) all_cases = all_cases.loc[:, cols] . # Load datasets for US population and Hospital beds per 1000 us_population = pd.read_csv(&#39;data/us_population.csv&#39;) hosp_beds = pd.read_csv(&#39;data/hospital_beds.csv&#39;) state_abbrev = pd.read_csv(&#39;data/us_state_names.csv&#39;) # add state abbreviations to us_population and hospital beds dataframe for state in state_abbrev[&#39;State&#39;].tolist(): # store state abbreviation in variable abbrev = state_abbrev.loc[state_abbrev[&#39;State&#39;] == state, &#39;Abbreviation&#39;].tolist()[0] # add abbrev to new column &#39;Abbreviation&#39; in us_population df us_population.loc[us_population[&#39;State&#39;] == state, &#39;Abbreviation&#39;] = abbrev # add abbrev to new column in hosp_beds df hosp_beds.loc[hosp_beds[&#39;Location&#39;] == state, &#39;Abbreviation&#39;] = abbrev # change order of columns of us_population cols = list(us_population) cols.insert(2, cols.pop(cols.index(&#39;Abbreviation&#39;))) us_population = us_population.loc[:, cols] # drop unnecessary columns of us_population us_population = us_population.drop(columns=[&#39;rank&#39;, &#39;Growth&#39;, &#39;Pop2018&#39;, &#39;Pop2010&#39;, &#39;growthSince2010&#39;, &#39;Percent&#39;, &#39;density&#39;]) # drop unnecessary columns of hosp_beds hosp_beds = hosp_beds.drop(columns=[&#39;Location&#39;, &#39;State/Local Government&#39;, &#39;Non-Profit&#39;, &#39;For-Profit&#39;]) # change order of columns of hosp_beds cols = list(hosp_beds) cols.insert(0, cols.pop(cols.index(&#39;Abbreviation&#39;))) hosp_beds = hosp_beds.loc[:, cols] . us_population.head() . State Abbreviation Pop . 0 Alabama | AL | 4908621 | . 1 Alaska | AK | 734002 | . 2 Arizona | AZ | 7378494 | . 3 Arkansas | AR | 3038999 | . 4 California | CA | 39937489 | . hosp_beds.head() . Abbreviation Total . 0 NaN | 2.4 | . 1 AL | 3.1 | . 2 AK | 2.2 | . 3 AZ | 1.9 | . 4 AR | 3.2 | . # filter out non-existing states like &#39;AS&#39; all_cases = all_cases[all_cases[&#39;state&#39;].isin(state_abbrev[&#39;Abbreviation&#39;].tolist())] . # see what filtered dataframe looks like all_cases.head() . date state positive active hospitalizedCurrently hospitalizedCumulative inIcuCurrently onVentilatorCurrently recovered dataQualityGrade ... totalTestsViral positiveTestsViral negativeTestsViral positiveCasesViral commercialScore negativeRegularScore negativeScore positiveScore score grade . 0 2020-06-26 | AK | 836.0 | 303.0 | 12.0 | NaN | NaN | 2.0 | 519.0 | A | ... | 101792.0 | NaN | NaN | NaN | 0 | 0 | 0 | 0 | 0 | NaN | . 1 2020-06-26 | AL | 34183.0 | 14410.0 | 658.0 | 2653.0 | NaN | NaN | 18866.0 | B | ... | NaN | NaN | NaN | 33717.0 | 0 | 0 | 0 | 0 | 0 | NaN | . 2 2020-06-26 | AR | 18062.0 | 5695.0 | 284.0 | 1300.0 | NaN | 61.0 | 12127.0 | A | ... | NaN | NaN | NaN | 18740.0 | 0 | 0 | 0 | 0 | 0 | NaN | . 4 2020-06-26 | AZ | 66548.0 | 56624.0 | 2110.0 | 4514.0 | 581.0 | 312.0 | 8389.0 | A+ | ... | 479330.0 | NaN | NaN | 66055.0 | 0 | 0 | 0 | 0 | 0 | NaN | . 5 2020-06-26 | CA | 200461.0 | NaN | 5639.0 | NaN | 1570.0 | NaN | NaN | B | ... | 3771314.0 | NaN | NaN | 200461.0 | 0 | 0 | 0 | 0 | 0 | NaN | . 5 rows × 25 columns . # Split dataframes by date df_split_by_date = dict(tuple(all_cases.groupby(&#39;date&#39;))) # Split dataframes by state df_split_by_state = dict(tuple(all_cases.groupby(&#39;state&#39;))) . # merge dataframes us_population and all_cases df_merge_uspop = all_cases.merge(us_population, how=&#39;left&#39;, left_on=&#39;state&#39;, right_on=&#39;Abbreviation&#39;) df_merge_uspop = df_merge_uspop.drop(columns=[&#39;Abbreviation&#39;]) df_merge_uspop = df_merge_uspop.rename(columns={&#39;Pop&#39;: &#39;population&#39;}) # change location of &#39;population&#39; column cols = list(df_merge_uspop) cols.insert(2, cols.pop(cols.index(&#39;population&#39;))) df_merge_uspop = df_merge_uspop.loc[:, cols] # merge dataframes hosp_beds and df_merge_uspop df_merge_hosp = df_merge_uspop.merge(hosp_beds, how=&#39;left&#39;, left_on=&#39;state&#39;, right_on=&#39;Abbreviation&#39;) df_merge_hosp = df_merge_hosp.drop(columns=[&#39;Abbreviation&#39;]) all_cases = df_merge_hosp.rename(columns={&#39;Total&#39;: &#39;bedsPerThousand&#39;}) . all_cases.head() . date state population positive active hospitalizedCurrently hospitalizedCumulative inIcuCurrently onVentilatorCurrently recovered ... negativeTestsViral positiveCasesViral commercialScore negativeRegularScore negativeScore positiveScore score grade State bedsPerThousand . 0 2020-06-26 | AK | 734002 | 836.0 | 303.0 | 12.0 | NaN | NaN | 2.0 | 519.0 | ... | NaN | NaN | 0 | 0 | 0 | 0 | 0 | NaN | Alaska | 2.2 | . 1 2020-06-26 | AL | 4908621 | 34183.0 | 14410.0 | 658.0 | 2653.0 | NaN | NaN | 18866.0 | ... | NaN | 33717.0 | 0 | 0 | 0 | 0 | 0 | NaN | Alabama | 3.1 | . 2 2020-06-26 | AR | 3038999 | 18062.0 | 5695.0 | 284.0 | 1300.0 | NaN | 61.0 | 12127.0 | ... | NaN | 18740.0 | 0 | 0 | 0 | 0 | 0 | NaN | Arkansas | 3.2 | . 3 2020-06-26 | AZ | 7378494 | 66548.0 | 56624.0 | 2110.0 | 4514.0 | 581.0 | 312.0 | 8389.0 | ... | NaN | 66055.0 | 0 | 0 | 0 | 0 | 0 | NaN | Arizona | 1.9 | . 4 2020-06-26 | CA | 39937489 | 200461.0 | NaN | 5639.0 | NaN | 1570.0 | NaN | NaN | ... | NaN | 200461.0 | 0 | 0 | 0 | 0 | 0 | NaN | California | 1.8 | . 5 rows × 28 columns . # Calculate the total beds, and add the column all_cases[&#39;total_beds&#39;] = all_cases[&#39;population&#39;] / 1000 * all_cases[&#39;bedsPerThousand&#39;] . # change abbreviations to state names all_cases = all_cases.rename(columns={&#39;state&#39;: &#39;abbrev&#39;}) all_cases = all_cases.rename(columns={&#39;State&#39;: &#39;state&#39;}) . # change location of &#39;state&#39; column cols = list(all_cases) cols.insert(1, cols.pop(cols.index(&#39;state&#39;))) all_cases = all_cases.loc[:, cols] . all_cases.head() . date state abbrev population positive active hospitalizedCurrently hospitalizedCumulative inIcuCurrently onVentilatorCurrently ... negativeTestsViral positiveCasesViral commercialScore negativeRegularScore negativeScore positiveScore score grade bedsPerThousand total_beds . 0 2020-06-26 | Alaska | AK | 734002 | 836.0 | 303.0 | 12.0 | NaN | NaN | 2.0 | ... | NaN | NaN | 0 | 0 | 0 | 0 | 0 | NaN | 2.2 | 1614.8044 | . 1 2020-06-26 | Alabama | AL | 4908621 | 34183.0 | 14410.0 | 658.0 | 2653.0 | NaN | NaN | ... | NaN | 33717.0 | 0 | 0 | 0 | 0 | 0 | NaN | 3.1 | 15216.7251 | . 2 2020-06-26 | Arkansas | AR | 3038999 | 18062.0 | 5695.0 | 284.0 | 1300.0 | NaN | 61.0 | ... | NaN | 18740.0 | 0 | 0 | 0 | 0 | 0 | NaN | 3.2 | 9724.7968 | . 3 2020-06-26 | Arizona | AZ | 7378494 | 66548.0 | 56624.0 | 2110.0 | 4514.0 | 581.0 | 312.0 | ... | NaN | 66055.0 | 0 | 0 | 0 | 0 | 0 | NaN | 1.9 | 14019.1386 | . 4 2020-06-26 | California | CA | 39937489 | 200461.0 | NaN | 5639.0 | NaN | 1570.0 | NaN | ... | NaN | 200461.0 | 0 | 0 | 0 | 0 | 0 | NaN | 1.8 | 71887.4802 | . 5 rows × 29 columns . Load and clean JHU data | Merge JHU dataset with main dataset | . # This cell takes some time, as it needs to connect to Kaggle Servers to retrieve data kaggle.api.authenticate() kaggle.api.dataset_download_files(&#39;benhamner/jhucovid19&#39;, path=&#39;./kaggle/input/jhucovid19/&#39;, unzip=True) . # Get Time-Series Data of cases as Pandas DataFrame dir_jhu = &#39;./kaggle/input/jhucovid19/csse_covid_19_data/csse_covid_19_daily_reports&#39; df_list = [] for dirname, _, files in os.walk(dir_jhu): for file in files: if &#39;gitignore&#39; not in file and &#39;README&#39; not in file: full_dir = os.path.join(dirname, file) df_list.append(pd.read_csv(full_dir)) jhu_df = pd.concat(df_list, axis=0, ignore_index=True, sort=True) # convert Last Update columns to datetime format jhu_df.loc[:, &#39;Last Update&#39;] = pd.to_datetime(jhu_df[&#39;Last Update&#39;]).apply(lambda x: x.date()) jhu_df.loc[:, &#39;Last_Update&#39;] = pd.to_datetime(jhu_df[&#39;Last_Update&#39;]).apply(lambda x: x.date()) # Combine Last Update with Last_Update jhu_df[&#39;LastUpdate&#39;] = jhu_df[&#39;Last_Update&#39;].combine_first(jhu_df[&#39;Last Update&#39;]) # Combine Country/Region with Country_Region jhu_df[&#39;CountryRegion&#39;] = jhu_df[&#39;Country/Region&#39;].combine_first(jhu_df[&#39;Country_Region&#39;]) # Retrieve only US data jhu_df = jhu_df[jhu_df[&#39;CountryRegion&#39;]==&#39;US&#39;] # Combine Province/State with Province_State jhu_df[&#39;ProvinceState&#39;] = jhu_df[&#39;Province/State&#39;].combine_first(jhu_df[&#39;Province_State&#39;]) # Drop unnecessary columns jhu_df = jhu_df.drop([&#39;Admin2&#39;, &#39;Lat&#39;, &#39;Latitude&#39;, &#39;Long_&#39;, &#39;Longitude&#39;, &#39;Combined_Key&#39;, &#39;Country/Region&#39;, &#39;Country_Region&#39;, &#39;Province/State&#39;, &#39;Province_State&#39;, &#39;Last Update&#39;, &#39;Last_Update&#39;, &#39;FIPS&#39;], axis=1) # Change column order cols = list(jhu_df) cols.insert(0, cols.pop(cols.index(&#39;CountryRegion&#39;))) cols.insert(1, cols.pop(cols.index(&#39;ProvinceState&#39;))) cols.insert(2, cols.pop(cols.index(&#39;LastUpdate&#39;))) jhu_df = jhu_df.loc[:, cols] # Change region to known US states state_abbrs_dict = {} for state in us.states.STATES: state_abbrs_dict[state.abbr] = state.name def toState(input_state, mapping): abbreviation = input_state.rstrip()[-2:] try: return_value = mapping[abbreviation] except KeyError: return_value = input_state return return_value jhu_df[&#39;ProvinceState&#39;] = jhu_df[&#39;ProvinceState&#39;].apply(lambda x: toState(x, state_abbrs_dict) if x != &#39;Washington, D.C.&#39; else &#39;District of Columbia&#39;) # Filter out unknown states jhu_df = jhu_df[jhu_df[&#39;ProvinceState&#39;].isin(all_cases.state.unique().tolist())] # Merge-sum rows with same date and State jhu_df = jhu_df.groupby([&#39;LastUpdate&#39;, &#39;ProvinceState&#39;]).agg( { &#39;Active&#39;: sum, &#39;Confirmed&#39;: sum, &#39;Deaths&#39;: sum, &#39;Recovered&#39;: sum } ).reset_index() jhu_df.tail() . LastUpdate ProvinceState Active Confirmed Deaths Recovered . 5190 2020-06-19 | Virginia | 54652.0 | 56238.0 | 1586.0 | 0.0 | . 5191 2020-06-19 | Washington | 25947.0 | 27192.0 | 1245.0 | 0.0 | . 5192 2020-06-19 | West Virginia | 2330.0 | 2418.0 | 88.0 | 0.0 | . 5193 2020-06-19 | Wisconsin | 23157.0 | 23876.0 | 719.0 | 0.0 | . 5194 2020-06-19 | Wyoming | 1126.0 | 1144.0 | 18.0 | 0.0 | . # Now that we have the JHU dataset relatively cleaned # we can go ahead and merge its data with our main dataset for i, row in all_cases.iterrows(): last_update = all_cases.at[i, &#39;date&#39;] state = all_cases.at[i, &#39;state&#39;] matching_row = jhu_df[jhu_df[&#39;ProvinceState&#39;] == state] matching_row = matching_row[matching_row[&#39;LastUpdate&#39;] == last_update].reset_index() if len(matching_row.values) &gt; 0: #all_cases.at[i, &#39;positive&#39;] = matching_row[&#39;Confirmed&#39;].values[0] all_cases.at[i, &#39;active&#39;] = matching_row[&#39;Active&#39;].values[0] #all_cases.at[i, &#39;recovered&#39;] = matching_row[&#39;Recovered&#39;].values[0] JHU was inconsistent, therefore removed #all_cases.at[i, &#39;death&#39;] = matching_row[&#39;Deaths&#39;].values[0] # Replace unknown recovery numbers with 0 if np.isnan(row[&#39;recovered&#39;]): all_cases.at[i, &#39;recovered&#39;] = 0 if all_cases.at[i, &#39;active&#39;] == 0 or np.isnan(row[&#39;active&#39;]): positive = all_cases.at[i, &#39;positive&#39;] recovered = all_cases.at[i, &#39;recovered&#39;] dead = all_cases.at[i, &#39;death&#39;] all_cases.at[i, &#39;active&#39;] = positive - recovered - dead all_cases.tail() . date state abbrev population positive active hospitalizedCurrently hospitalizedCumulative inIcuCurrently onVentilatorCurrently ... negativeTestsViral positiveCasesViral commercialScore negativeRegularScore negativeScore positiveScore score grade bedsPerThousand total_beds . 5825 2020-01-26 | Washington | WA | 7797095 | 2.0 | 2.0 | NaN | NaN | NaN | NaN | ... | NaN | NaN | 0 | 0 | 0 | 0 | 0 | NaN | 1.7 | 13255.0615 | . 5826 2020-01-25 | Washington | WA | 7797095 | 2.0 | 2.0 | NaN | NaN | NaN | NaN | ... | NaN | NaN | 0 | 0 | 0 | 0 | 0 | NaN | 1.7 | 13255.0615 | . 5827 2020-01-24 | Washington | WA | 7797095 | 2.0 | 2.0 | NaN | NaN | NaN | NaN | ... | NaN | NaN | 0 | 0 | 0 | 0 | 0 | NaN | 1.7 | 13255.0615 | . 5828 2020-01-23 | Washington | WA | 7797095 | 2.0 | 2.0 | NaN | NaN | NaN | NaN | ... | NaN | NaN | 0 | 0 | 0 | 0 | 0 | NaN | 1.7 | 13255.0615 | . 5829 2020-01-22 | Washington | WA | 7797095 | 2.0 | 2.0 | NaN | NaN | NaN | NaN | ... | NaN | NaN | 0 | 0 | 0 | 0 | 0 | NaN | 1.7 | 13255.0615 | . 5 rows × 29 columns . # Save formatted dataset offline in case of disaster dataset_file = &#39;results/all_cases.csv&#39; all_cases.to_csv(dataset_file) . # convert date to datetime format all_cases[&#39;date&#39;] = pd.to_datetime(all_cases[&#39;date&#39;]) . An Exploratory data analysis of the US dataset . Basic triad of the dataset: validating data types and data integrity of each row . dataset_file = &#39;results/all_cases.csv&#39; covid_df = pd.read_csv(dataset_file, index_col=0) # convert date to datetime format covid_df[&#39;date&#39;] = pd.to_datetime(covid_df[&#39;date&#39;]) covid_df.info() # set float format to 3 decimals pd.set_option(&#39;display.float_format&#39;, lambda x: &#39;%.3f&#39; % x) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 5830 entries, 0 to 5829 Data columns (total 29 columns): date 5830 non-null datetime64[ns] state 5830 non-null object abbrev 5830 non-null object population 5830 non-null int64 positive 5830 non-null float64 active 5830 non-null float64 hospitalizedCurrently 3551 non-null float64 hospitalizedCumulative 3162 non-null float64 inIcuCurrently 1833 non-null float64 onVentilatorCurrently 1630 non-null float64 recovered 5830 non-null float64 dataQualityGrade 4896 non-null object lastUpdateEt 5475 non-null object dateModified 5475 non-null object checkTimeEt 5475 non-null object death 5830 non-null float64 hospitalized 3162 non-null float64 totalTestsViral 1544 non-null float64 positiveTestsViral 515 non-null float64 negativeTestsViral 514 non-null float64 positiveCasesViral 3010 non-null float64 commercialScore 5830 non-null int64 negativeRegularScore 5830 non-null int64 negativeScore 5830 non-null int64 positiveScore 5830 non-null int64 score 5830 non-null int64 grade 0 non-null float64 bedsPerThousand 5830 non-null float64 total_beds 5830 non-null float64 dtypes: datetime64[ns](1), float64(16), int64(6), object(6) memory usage: 1.3+ MB . covid_df.head() . date state abbrev population positive active hospitalizedCurrently hospitalizedCumulative inIcuCurrently onVentilatorCurrently ... negativeTestsViral positiveCasesViral commercialScore negativeRegularScore negativeScore positiveScore score grade bedsPerThousand total_beds . 0 2020-06-26 | Alaska | AK | 734002 | 836.000 | 303.000 | 12.000 | nan | nan | 2.000 | ... | nan | nan | 0 | 0 | 0 | 0 | 0 | nan | 2.200 | 1614.804 | . 1 2020-06-26 | Alabama | AL | 4908621 | 34183.000 | 14410.000 | 658.000 | 2653.000 | nan | nan | ... | nan | 33717.000 | 0 | 0 | 0 | 0 | 0 | nan | 3.100 | 15216.725 | . 2 2020-06-26 | Arkansas | AR | 3038999 | 18062.000 | 5695.000 | 284.000 | 1300.000 | nan | 61.000 | ... | nan | 18740.000 | 0 | 0 | 0 | 0 | 0 | nan | 3.200 | 9724.797 | . 3 2020-06-26 | Arizona | AZ | 7378494 | 66548.000 | 56624.000 | 2110.000 | 4514.000 | 581.000 | 312.000 | ... | nan | 66055.000 | 0 | 0 | 0 | 0 | 0 | nan | 1.900 | 14019.139 | . 4 2020-06-26 | California | CA | 39937489 | 200461.000 | 194649.000 | 5639.000 | nan | 1570.000 | nan | ... | nan | 200461.000 | 0 | 0 | 0 | 0 | 0 | nan | 1.800 | 71887.480 | . 5 rows × 29 columns . The NaN values may indicate that there were no to few Covid-19 patients at these date points. We further analyse the statistical values of the dataset columns to ensure data integrity and accuracy. . covid_df.describe() # TODO rounding up the numbers . population positive active hospitalizedCurrently hospitalizedCumulative inIcuCurrently onVentilatorCurrently recovered death hospitalized ... negativeTestsViral positiveCasesViral commercialScore negativeRegularScore negativeScore positiveScore score grade bedsPerThousand total_beds . count 5830.000 | 5830.000 | 5830.000 | 3551.000 | 3162.000 | 1833.000 | 1630.000 | 5830.000 | 5830.000 | 3162.000 | ... | 514.000 | 3010.000 | 5830.000 | 5830.000 | 5830.000 | 5830.000 | 5830.000 | 0.000 | 5830.000 | 5830.000 | . mean 6543778.006 | 20671.992 | 18487.479 | 1032.840 | 4317.587 | 447.338 | 228.415 | 4318.329 | 1080.164 | 4317.587 | ... | 283412.642 | 31732.312 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 2.625 | 15807.419 | . std 7387219.213 | 46209.844 | 41691.369 | 1942.496 | 12899.042 | 698.865 | 332.295 | 10788.010 | 2889.998 | 12899.042 | ... | 376950.308 | 56252.909 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 0.744 | 16159.931 | . min 567025.000 | 0.000 | 0.000 | 1.000 | 0.000 | 2.000 | 0.000 | 0.000 | 0.000 | 0.000 | ... | 17.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 1.600 | 1318.928 | . 25% 1778070.000 | 624.250 | 537.250 | 121.000 | 218.250 | 83.000 | 36.000 | 0.000 | 12.000 | 218.250 | ... | 48368.750 | 4965.250 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 2.100 | 3773.952 | . 50% 4499692.000 | 4920.000 | 4439.000 | 402.000 | 946.000 | 186.000 | 94.000 | 189.000 | 140.000 | 946.000 | ... | 134948.500 | 13536.500 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 2.500 | 11557.920 | . 75% 7797095.000 | 20155.750 | 17265.250 | 1044.000 | 3159.500 | 492.000 | 252.500 | 2958.500 | 759.500 | 3159.500 | ... | 322553.250 | 34848.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 3.100 | 19124.737 | . max 39937489.000 | 391220.000 | 356899.000 | 18825.000 | 89995.000 | 5225.000 | 2425.000 | 76282.000 | 24814.000 | 89995.000 | ... | 1943604.000 | 391220.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 4.800 | 71887.480 | . 8 rows × 22 columns . # drop unnecessary columns covid_cleaned = covid_df.drop([&#39;hospitalized&#39;, &#39;bedsPerThousand&#39;], axis=1) covid_100k = covid_cleaned.copy() # list of columns to transform to per 100k columns_list = [&#39;positive&#39;, &#39;active&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalizedCurrently&#39;, &#39;hospitalizedCumulative&#39;, &#39;inIcuCurrently&#39;, &#39;onVentilatorCurrently&#39;, &#39;total_beds&#39;] # add columns per 100k for column in columns_list: if column == &#39;total_beds&#39;: covid_100k[&#39;BedsPer100k&#39;.format(column)] = (covid_cleaned.loc[:, column] / covid_cleaned.loc[:, &#39;population&#39;]) * 100000 else: covid_100k[&#39;{}_100k&#39;.format(column)] = (covid_cleaned.loc[:, column] / covid_cleaned.loc[:, &#39;population&#39;]) * 100000 covid_100k = covid_100k.drop(columns_list, axis=1) . covid_100k[&#39;date&#39;] = pd.to_datetime(covid_100k[&#39;date&#39;]) start_date = &#39;2020-04-18&#39; end_date = &#39;2020-05-19&#39; mask = (covid_100k[&#39;date&#39;] &gt; start_date) &amp; (covid_100k[&#39;date&#39;] &lt;= end_date) covid_100k_last_month = covid_100k.loc[mask] . covid_100k_last_month_part1 = covid_100k_last_month.groupby(&#39;date&#39;).sum().loc[:, [&#39;positive_100k&#39;,&#39;active_100k&#39;,&#39;recovered_100k&#39;,&#39;death_100k&#39;,&#39;hospitalizedCumulative_100k&#39;]].diff(periods=1, axis=0) covid_100k_last_month_part2 = covid_100k_last_month.groupby(&#39;date&#39;).sum().loc[:, [&#39;inIcuCurrently_100k&#39;,&#39;onVentilatorCurrently_100k&#39;,&#39;BedsPer100k&#39;]] final_100k_last_month = covid_100k_last_month_part1.merge(covid_100k_last_month_part2, left_index=True, right_index=True) . final_100k_last_month.head() . positive_100k active_100k recovered_100k death_100k hospitalizedCumulative_100k inIcuCurrently_100k onVentilatorCurrently_100k BedsPer100k . date . 2020-04-19 nan | nan | nan | nan | nan | 153.528 | 80.717 | 13440.000 | . 2020-04-20 413.759 | 391.692 | 35.481 | 25.728 | 22.652 | 156.581 | 79.710 | 13440.000 | . 2020-04-21 387.394 | 360.446 | 65.218 | 30.520 | 31.446 | 166.081 | 78.603 | 13440.000 | . 2020-04-22 428.601 | 989.954 | 412.625 | 28.780 | 36.181 | 167.561 | 78.032 | 13440.000 | . 2020-04-23 452.031 | -2213.482 | 72.921 | 26.282 | 28.842 | 166.277 | 94.521 | 13440.000 | . final_100k_last_month.describe() . positive_100k active_100k recovered_100k death_100k hospitalizedCumulative_100k inIcuCurrently_100k onVentilatorCurrently_100k BedsPer100k . count 30.000 | 30.000 | 30.000 | 30.000 | 30.000 | 31.000 | 31.000 | 31.000 | . mean 399.188 | 364.943 | 147.172 | 23.271 | 39.160 | 134.117 | 73.503 | 13440.000 | . std 58.939 | 634.169 | 81.341 | 5.781 | 43.524 | 19.860 | 8.141 | 0.000 | . min 287.019 | -2213.482 | 35.481 | 13.315 | 9.507 | 109.602 | 61.622 | 13440.000 | . 25% 348.980 | 314.204 | 80.563 | 18.439 | 22.991 | 118.222 | 66.261 | 13440.000 | . 50% 405.026 | 366.234 | 127.774 | 24.119 | 28.295 | 127.613 | 74.706 | 13440.000 | . 75% 432.647 | 419.664 | 212.491 | 26.201 | 32.754 | 149.768 | 79.157 | 13440.000 | . max 544.349 | 2291.210 | 412.625 | 33.917 | 246.371 | 167.561 | 94.521 | 13440.000 | . # save description cleaned dataset to csv describe_file = &#39;results/final_100k_last_month.csv&#39; final_100k_last_month.describe().to_csv(describe_file) . B. Graphical Exploratory Analysis . Plotting histograms, scatterplots and boxplots to assess the distribution of the entire US dataset. . # Omitting the categorical (states/abbreviations) and time columns # There must be an easier way for you, but this was the easiest way I could think of covid_cleaned[&#39;date&#39;] = pd.to_datetime(covid_cleaned[&#39;date&#39;]) # mask data for last month start_date = &#39;2020-04-18&#39; end_date = &#39;2020-05-19&#39; mask = (covid_cleaned[&#39;date&#39;] &gt; start_date) &amp; (covid_cleaned[&#39;date&#39;] &lt;= end_date) covid_cleaned_last_month = covid_cleaned.loc[mask] plot_df = covid_cleaned_last_month[[&#39;population&#39;, &#39;active&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;onVentilatorCurrently&#39;, &#39;total_beds&#39;]] plot_df_last_month = covid_100k_last_month[[&#39;population&#39;, &#39;active_100k&#39;, &#39;recovered_100k&#39;, &#39;death_100k&#39;, &#39;hospitalizedCurrently_100k&#39;, &#39;inIcuCurrently_100k&#39;, &#39;onVentilatorCurrently_100k&#39;, &#39;BedsPer100k&#39;]] . timeseries_usa_df = covid_100k.loc[:, [&#39;date&#39;, &#39;positive_100k&#39;, &#39;active_100k&#39;, &#39;recovered_100k&#39;, &#39;death_100k&#39;, &#39;hospitalizedCurrently_100k&#39;, &#39;inIcuCurrently_100k&#39;, &#39;onVentilatorCurrently_100k&#39;, &#39;BedsPer100k&#39;]].groupby(&#39;date&#39;).sum().reset_index() # timeseries_usa_df[&#39;log_positive&#39;] = np.log(timeseries_usa_df[&#39;positive_100k&#39;]) # timeseries_usa_df[&#39;log_active&#39;] = np.log(timeseries_usa_df[&#39;active_100k&#39;]) # timeseries_usa_df[&#39;log_recovered&#39;] = np.log(timeseries_usa_df[&#39;recovered_100k&#39;]) # timeseries_usa_df[&#39;log_death&#39;] = np.log(timeseries_usa_df[&#39;death_100k&#39;]) . timeseries_usa_df.tail() . date positive_100k active_100k recovered_100k death_100k hospitalizedCurrently_100k inIcuCurrently_100k onVentilatorCurrently_100k BedsPer100k . 152 2020-06-22 | 32457.545 | 18905.435 | 12018.320 | 1533.791 | 385.922 | 67.908 | 36.848 | 13440.000 | . 153 2020-06-23 | 32860.514 | 19133.883 | 12183.722 | 1542.909 | 403.069 | 71.078 | 37.684 | 13440.000 | . 154 2020-06-24 | 33315.285 | 19401.954 | 12359.391 | 1553.940 | 408.570 | 68.612 | 36.820 | 13440.000 | . 155 2020-06-25 | 33812.912 | 19730.969 | 12498.864 | 1583.079 | 414.087 | 67.864 | 36.962 | 13440.000 | . 156 2020-06-26 | 34335.924 | 20098.997 | 12643.998 | 1592.929 | 404.115 | 67.051 | 34.318 | 13440.000 | . x_dates = timeseries_usa_df[&#39;date&#39;].tolist() y_hospitalized = timeseries_usa_df[&#39;hospitalizedCurrently_100k&#39;].tolist() y_icu = timeseries_usa_df[&#39;inIcuCurrently_100k&#39;].tolist() y_pos = timeseries_usa_df[&#39;positive_100k&#39;].tolist() y_act = timeseries_usa_df[&#39;active_100k&#39;].tolist() y_rec = timeseries_usa_df[&#39;recovered_100k&#39;].tolist() y_death = timeseries_usa_df[&#39;death_100k&#39;].tolist() y_vent = timeseries_usa_df[&#39;onVentilatorCurrently_100k&#39;].tolist() y_beds = timeseries_usa_df[&#39;BedsPer100k&#39;].tolist() hospitalized_trace = go.Scatter(x=x_dates, y=y_hospitalized, name=&#39;Hospitalized&#39;) icu_trace = go.Scatter(x=x_dates, y=y_icu, name=&#39;ICU&#39;) pos_trace = go.Scatter(x=x_dates, y=y_pos, name=&#39;Positive&#39;) act_trace = go.Scatter(x=x_dates, y=y_act, name=&#39;Active&#39;) rec_trace = go.Scatter(x=x_dates, y=y_rec, name=&#39;Recovered&#39;) death_trace = go.Scatter(x=x_dates, y=y_death, name=&#39;Killed&#39;) vent_trace = go.Scatter(x=x_dates, y=y_vent, name=&#39;On Ventilator&#39;) beds_trace = go.Scatter(x=x_dates, y=y_beds, name=&#39;Beds&#39;) layout = go.Layout(xaxis_title=&#39;Date&#39;, yaxis_title=&#39;Count/100k&#39;, title_x=0.5, xaxis_tickformat = &#39;%d-%m-%Y&#39;) fig = make_subplots(rows=1, cols=2) fig = go.Figure([hospitalized_trace, icu_trace, vent_trace], layout=layout) fig.show() fig = go.Figure([pos_trace, rec_trace, death_trace], layout=layout) fig.show() . covid_100k . date state abbrev population dataQualityGrade lastUpdateEt dateModified checkTimeEt totalTestsViral positiveTestsViral ... grade positive_100k active_100k recovered_100k death_100k hospitalizedCurrently_100k hospitalizedCumulative_100k inIcuCurrently_100k onVentilatorCurrently_100k BedsPer100k . 0 2020-06-26 | Alaska | AK | 734002 | A | 6/26/2020 00:00 | 2020-06-26T00:00:00Z | 06/25 20:00 | 101792.000 | nan | ... | nan | 113.896 | 41.281 | 70.708 | 1.907 | 1.635 | nan | nan | 0.272 | 220.000 | . 1 2020-06-26 | Alabama | AL | 4908621 | B | 6/26/2020 11:00 | 2020-06-26T11:00:00Z | 06/26 07:00 | nan | nan | ... | nan | 696.387 | 293.565 | 384.344 | 18.478 | 13.405 | 54.048 | nan | nan | 310.000 | . 2 2020-06-26 | Arkansas | AR | 3038999 | A | 6/26/2020 14:40 | 2020-06-26T14:40:00Z | 06/26 10:40 | nan | nan | ... | nan | 594.340 | 187.397 | 399.046 | 7.897 | 9.345 | 42.777 | nan | 2.007 | 320.000 | . 3 2020-06-26 | Arizona | AZ | 7378494 | A+ | 6/26/2020 00:00 | 2020-06-26T00:00:00Z | 06/25 20:00 | 479330.000 | nan | ... | nan | 901.918 | 767.419 | 113.695 | 20.804 | 28.597 | 61.178 | 7.874 | 4.229 | 190.000 | . 4 2020-06-26 | California | CA | 39937489 | B | 6/26/2020 00:00 | 2020-06-26T00:00:00Z | 06/25 20:00 | 3771314.000 | nan | ... | nan | 501.937 | 487.384 | 0.000 | 14.553 | 14.120 | nan | 3.931 | nan | 180.000 | . 5 2020-06-26 | Colorado | CO | 5845526 | A | 6/25/2020 00:00 | 2020-06-25T00:00:00Z | 06/24 20:00 | nan | nan | ... | nan | 538.514 | 434.486 | 75.477 | 28.552 | 4.225 | 92.139 | nan | nan | 190.000 | . 6 2020-06-26 | Connecticut | CT | 3563077 | B | 6/25/2020 20:30 | 2020-06-25T20:30:00Z | 06/25 16:30 | 414889.000 | nan | ... | nan | 1292.675 | 945.784 | 226.013 | 120.879 | 3.564 | 288.178 | nan | nan | 200.000 | . 7 2020-06-26 | District of Columbia | DC | 720687 | A+ | 6/25/2020 00:00 | 2020-06-25T00:00:00Z | 06/24 20:00 | nan | nan | ... | nan | 1413.235 | 1172.909 | 164.565 | 75.761 | 20.397 | nan | 6.660 | 4.024 | 440.000 | . 8 2020-06-26 | Delaware | DE | 982895 | A | 6/25/2020 18:00 | 2020-06-25T18:00:00Z | 06/25 14:00 | nan | nan | ... | nan | 1120.873 | 391.598 | 677.692 | 51.582 | 7.936 | nan | nan | nan | 220.000 | . 9 2020-06-26 | Florida | FL | 21992985 | A | 6/25/2020 23:59 | 2020-06-25T23:59:00Z | 06/25 19:59 | 2107048.000 | 159793.000 | ... | nan | 559.087 | 543.337 | 0.000 | 15.750 | nan | 64.934 | nan | nan | 260.000 | . 10 2020-06-26 | Georgia | GA | 10736059 | A | 6/26/2020 14:50 | 2020-06-26T14:50:00Z | 06/26 10:50 | 771028.000 | 66510.000 | ... | nan | 679.905 | 654.104 | 0.000 | 25.801 | 11.028 | 98.779 | nan | nan | 240.000 | . 11 2020-06-26 | Hawaii | HI | 1412687 | D | 6/25/2020 18:00 | 2020-06-25T18:00:00Z | 06/25 14:00 | 84910.000 | 850.000 | ... | nan | 60.169 | 9.698 | 49.268 | 1.203 | nan | 7.716 | nan | nan | 190.000 | . 12 2020-06-26 | Iowa | IA | 3179849 | A+ | 6/26/2020 00:00 | 2020-06-26T00:00:00Z | 06/25 20:00 | nan | nan | ... | nan | 870.670 | 304.071 | 544.460 | 22.139 | 4.434 | nan | 1.321 | 0.755 | 300.000 | . 13 2020-06-26 | Idaho | ID | 1826156 | A | 6/25/2020 19:00 | 2020-06-25T19:00:00Z | 06/25 15:00 | 81871.000 | nan | ... | nan | 266.407 | 58.210 | 203.269 | 4.928 | nan | 16.592 | nan | nan | 190.000 | . 14 2020-06-26 | Illinois | IL | 12659682 | A | 6/26/2020 00:00 | 2020-06-26T00:00:00Z | 06/25 20:00 | 1490952.000 | nan | ... | nan | 1116.489 | 1060.817 | 0.000 | 55.673 | 11.975 | nan | 3.160 | 1.777 | 250.000 | . 15 2020-06-26 | Indiana | IN | 6745354 | A+ | 6/25/2020 23:59 | 2020-06-25T23:59:00Z | 06/25 19:59 | nan | nan | ... | nan | 654.376 | 120.809 | 495.096 | 38.471 | 10.259 | 102.945 | 4.166 | 1.394 | 270.000 | . 16 2020-06-26 | Kansas | KS | 2910357 | A | 6/26/2020 10:00 | 2020-06-26T10:00:00Z | 06/26 06:00 | nan | nan | ... | nan | 465.166 | 429.329 | 26.766 | 9.071 | nan | 38.758 | nan | nan | 330.000 | . 17 2020-06-26 | Kentucky | KY | 4499692 | B | 6/26/2020 00:00 | 2020-06-26T00:00:00Z | 06/25 20:00 | nan | nan | ... | nan | 330.223 | 235.038 | 82.895 | 12.290 | 8.601 | 57.537 | 1.645 | nan | 320.000 | . 18 2020-06-26 | Louisiana | LA | 4645184 | B | 6/26/2020 13:00 | 2020-06-26T13:00:00Z | 06/26 09:00 | nan | nan | ... | nan | 1179.049 | 253.747 | 856.629 | 68.673 | 15.069 | nan | nan | 1.572 | 330.000 | . 19 2020-06-26 | Massachusetts | MA | 6976597 | A+ | 6/26/2020 10:00 | 2020-06-26T10:00:00Z | 06/26 06:00 | 1020867.000 | nan | ... | nan | 1549.036 | 1434.181 | 0.000 | 114.855 | 11.338 | 161.841 | 2.236 | 1.419 | 230.000 | . 20 2020-06-26 | Maryland | MD | 6083116 | A | 6/26/2020 10:00 | 2020-06-26T10:00:00Z | 06/26 06:00 | 613513.000 | nan | ... | nan | 1086.861 | 954.609 | 80.600 | 51.651 | 8.006 | 176.308 | 3.123 | nan | 190.000 | . 21 2020-06-26 | Maine | ME | 1345790 | A | 6/25/2020 23:59 | 2020-06-25T23:59:00Z | 06/25 19:59 | 89510.000 | 3787.000 | ... | nan | 230.497 | 33.958 | 188.885 | 7.653 | 2.081 | 25.487 | 0.669 | 0.446 | 250.000 | . 22 2020-06-26 | Michigan | MI | 10045029 | A+ | 6/26/2020 00:00 | 2020-06-26T00:00:00Z | 06/25 20:00 | 998490.000 | 86113.000 | ... | nan | 690.182 | 138.427 | 490.690 | 61.065 | 5.545 | nan | 1.921 | 1.055 | 250.000 | . 23 2020-06-26 | Minnesota | MN | 5700671 | A | 6/25/2020 17:00 | 2020-06-25T17:00:00Z | 06/25 13:00 | 557278.000 | nan | ... | nan | 607.227 | 55.467 | 526.394 | 25.365 | 5.877 | 69.571 | 2.754 | nan | 250.000 | . 24 2020-06-26 | Missouri | MO | 6169270 | B | 6/26/2020 15:00 | 2020-06-26T15:00:00Z | 06/26 11:00 | 424214.000 | 23527.000 | ... | nan | 322.793 | 306.746 | 0.000 | 16.047 | 9.726 | nan | nan | 1.070 | 310.000 | . 25 2020-06-26 | Mississippi | MS | 2989260 | A | 6/25/2020 19:00 | 2020-06-25T19:00:00Z | 06/25 15:00 | 271734.000 | nan | ... | nan | 838.535 | 227.548 | 576.798 | 34.189 | 25.725 | 101.831 | 5.118 | 3.011 | 400.000 | . 26 2020-06-26 | Montana | MT | 1086759 | C | 6/26/2020 00:00 | 2020-06-26T00:00:00Z | 06/25 20:00 | nan | nan | ... | nan | 76.282 | 20.060 | 54.198 | 2.024 | 1.288 | 8.742 | nan | nan | 330.000 | . 27 2020-06-26 | North Carolina | NC | 10611862 | A | 6/26/2020 11:55 | 2020-06-26T11:55:00Z | 06/26 07:55 | nan | nan | ... | nan | 554.267 | 194.066 | 347.922 | 12.279 | 8.406 | nan | nan | nan | 210.000 | . 28 2020-06-26 | North Dakota | ND | 761723 | D | 6/26/2020 00:00 | 2020-06-26T00:00:00Z | 06/25 20:00 | 169838.000 | nan | ... | nan | 449.113 | 32.033 | 405.659 | 11.421 | 3.019 | 29.144 | nan | nan | 430.000 | . 29 2020-06-26 | Nebraska | NE | 1952570 | B | 6/25/2020 19:55 | 2020-06-25T19:55:00Z | 06/25 15:55 | nan | nan | ... | nan | 939.582 | 295.610 | 630.656 | 13.316 | 6.453 | 66.272 | nan | nan | 360.000 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 5800 2020-02-20 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 1.052 | 1.052 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5801 2020-02-19 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.885 | 0.885 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5802 2020-02-18 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.757 | 0.757 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5803 2020-02-17 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.641 | 0.641 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5804 2020-02-16 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.449 | 0.449 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5805 2020-02-15 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.359 | 0.359 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5806 2020-02-14 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.269 | 0.269 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5807 2020-02-13 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.231 | 0.231 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5808 2020-02-12 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.231 | 0.231 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5809 2020-02-11 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.218 | 0.218 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5810 2020-02-10 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.205 | 0.205 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5811 2020-02-09 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.167 | 0.167 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5812 2020-02-08 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.167 | 0.167 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5813 2020-02-07 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.154 | 0.154 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5814 2020-02-06 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.141 | 0.141 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5815 2020-02-05 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.103 | 0.103 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5816 2020-02-04 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.103 | 0.103 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5817 2020-02-03 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.090 | 0.090 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5818 2020-02-02 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.077 | 0.077 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5819 2020-02-01 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.051 | 0.051 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5820 2020-01-31 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.038 | 0.038 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5821 2020-01-30 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.038 | 0.038 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5822 2020-01-29 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.038 | 0.038 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5823 2020-01-28 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.026 | 0.026 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5824 2020-01-27 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.026 | 0.026 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5825 2020-01-26 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.026 | 0.026 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5826 2020-01-25 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.026 | 0.026 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5827 2020-01-24 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.026 | 0.026 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5828 2020-01-23 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.026 | 0.026 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5829 2020-01-22 | Washington | WA | 7797095 | NaN | NaN | NaN | NaN | nan | nan | ... | nan | 0.026 | 0.026 | 0.000 | 0.000 | nan | nan | nan | nan | 170.000 | . 5830 rows × 27 columns . # Timeseries plot fig, ax = plt.subplots(figsize = (16, 16)) ax.plot(covid_df.date, covid_df.hospitalizedCurrently) ax.set_title(&#39;Number of USA Patients Currently in ICU&#39;) # TODO change the X-axis to chip the year # TODO which timeseries plots do we need? # TODO how to temporarily remove the outliers? . Text(0.5, 1.0, &#39;Number of USA Patients Currently in ICU&#39;) . # get data from last day # plot_df_last_date = plot_df.loc[covid_df[&#39;date&#39;] == &#39;2020-05-18&#39;] # Plotting histograms to gain insight of the distribution shape, skewness and scale fig, axs = plt.subplots(4,2,figsize = (16, 16)) sns.set() for i, column in enumerate(plot_df_last_month.columns): if (i + 1) % 2 == 0: ax = axs[(i//2), 1] else: ax = axs[(i//2), 0] sns.distplot(plot_df_last_month[column], fit=norm, fit_kws=dict(label=&#39;normality&#39;), hist_kws=dict(color=&#39;plum&#39;, edgecolor=&#39;k&#39;, linewidth=1, label=&#39;frequency&#39;), ax=ax, color=&#39;#9d53ad&#39;) ax.legend(loc=&#39;upper right&#39;) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Looking at linearity and variance with scatterplots # Removing the target variable and saving it in another df target = plot_df.hospitalizedCurrently indep_var = plot_df.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var.columns): ax=fig.add_subplot(4, 3, i+1) sns.regplot(x=indep_var[col], y=target, data=indep_var, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;, &#39;label&#39;: &#39;hospitCurr&#39;}) plt.suptitle(&#39;Scatterplots with Target Hospitalized Patients Showing Growth Trajectories&#39;, fontsize=18) plt.legend() plt.tight_layout() fig.subplots_adjust(top=0.95) . # Assessing the normality of the distribution with a boxplot # Boxplot with removed outliers fig, ax = plt.subplots(figsize = (16, 12)) for i, col in enumerate(plot_df.columns): ax=fig.add_subplot(4, 3, i+1) sns.boxplot(x=plot_df[col], data=plot_df, color=&#39;lightblue&#39;, showfliers=False) plt.suptitle(&#39;Boxplots of Independent Variables&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # get data from last day plot_df_last_date = plot_df.loc[covid_df[&#39;date&#39;] == &#39;2020-05-18&#39;] fig, ax = plt.subplots(figsize = (16, 12)) for i, col in enumerate(plot_df_last_date.columns): ax=fig.add_subplot(4, 3, i+1) sns.boxplot(x=plot_df_last_date[col], data=plot_df, color=&#39;lightblue&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . Analysis of Hospitalizations by State . Since the normality of the independent variables is highly variable do to temporal and precision differences from each state, we further assess each state&#39;s data by viewing trends on the independent variables in both scatter and box-and-whisker plots. . New York: . # Split covid_df into subset with only NY values new_york = covid_df.loc[covid_df[&#39;abbrev&#39;] == &#39;NY&#39;] fig, ax = plt.subplots(figsize = (16, 12)) # Timeseries plt plt.plot(new_york.date, new_york.hospitalizedCurrently) plt.title(&#39;Number of Patients in NY Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) # TODO the code below can be deleted once we fix the date format in plots #set ticks every week ax.xaxis.set_major_locator(mdates.WeekdayLocator()) #set major ticks format ax.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%m&#39;)) . # Omit the categorical and date cols new_york = new_york[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;hospitalizedCumulative&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] . # Scatter plots NY # Split dependent var from independent variables target_ny = new_york.hospitalizedCurrently indep_var_ny = new_york.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_ny.columns): ax=fig.add_subplot(3, 3, i+1) sns.regplot(x=indep_var_ny[col], y=target_ny, data=indep_var_ny, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables NY&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of NY fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(new_york.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=new_york[col], data=new_york, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables NY&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . California: . cali = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;CA&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;California&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(cali.date, cali.hospitalizedCurrently) plt.title(&#39;Number of Patients in CA Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values cali[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] cali.head() # Omit the NaN cols cali = cali[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots CA # Split dependent var from independent variables target_ca = cali.hospitalizedCurrently indep_var_ca = cali.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_ca.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_ca[col], y=target_ca, data=indep_var_ca, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables CA&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of CA fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(cali.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=cali[col], data=cali, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables CA&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endcali . Texas: . texas = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;TX&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;Texas&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(texas.date, texas.hospitalizedCurrently) plt.title(&#39;Number of Patients in TX Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values texas[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] texas.head() # Omit the NaN cols texas = texas[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots TX # Split dependent var from independent variables target_tx = texas.hospitalizedCurrently indep_var_tx = texas.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_tx.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_tx[col], y=target_tx, data=indep_var_tx, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables TX&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of TX fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(texas.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=texas[col], data=texas, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables TX&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endtx . South Carolina: . sc = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;SC&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;South Carolina&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(sc.date, sc.hospitalizedCurrently) plt.title(&#39;Number of Patients in SC Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values sc[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] sc.head() # Omit the NaN cols sc = sc[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots SC # Split dependent var from independent variables target_sc = sc.hospitalizedCurrently indep_var_sc = sc.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_sc.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_sc[col], y=target_sc, data=indep_var_sc, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables SC&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of SC fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(sc.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=sc[col], data=sc, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables TX&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endsouthcarolina . Nevada: . nevada = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;NV&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;Nevada&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(nevada.date, nevada.hospitalizedCurrently) plt.title(&#39;Number of Patients in NV Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values nevada[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] nevada.head() # Omit the NaN cols nevada = nevada[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots NV # Split dependent var from independent variables target_nv = nevada.hospitalizedCurrently indep_var_nv = nevada.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_nv.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_nv[col], y=target_nv, data=indep_var_nv, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables NV&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of NV fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(nevada.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=nevada[col], data=nevada, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables NV&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endnevada . Arizona: . arizona = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;AZ&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;Arizona&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(arizona.date, arizona.hospitalizedCurrently) plt.title(&#39;Number of Patients in AZ Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values arizona[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] arizona.head() # Omit the NaN cols arizona = arizona[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots AZ # Split dependent var from independent variables target_az = arizona.hospitalizedCurrently indep_var_az = arizona.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_az.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_az[col], y=target_az, data=indep_var_az, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables AZ&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of AZ fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(arizona.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=arizona[col], data=arizona, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables AZ&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endarizona . Mississippi: . mississippi = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;MS&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;Mississippi&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(mississippi.date, mississippi.hospitalizedCurrently) plt.title(&#39;Number of Patients in MS Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values mississippi[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] mississippi.head() # Omit the NaN cols mississippi = mississippi[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots MS # Split dependent var from independent variables target_ms = texas.hospitalizedCurrently indep_var_ms = texas.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_ms.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_ms[col], y=target_ms, data=indep_var_ms, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables MS&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of MS fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(texas.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=mississippi[col], data=mississippi, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables MS&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endmississippi . Utah: . utah = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;UT&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;Utah&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(utah.date, utah.hospitalizedCurrently) plt.title(&#39;Number of Patients in UT Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values utah[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] utah.head() # Omit the NaN cols utah = utah[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots UT # Split dependent var from independent variables target_ut = utah.hospitalizedCurrently indep_var_ut = utah.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_tx.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_ut[col], y=target_ut, data=indep_var_ut, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables UT&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endutah . Georgia: . georgia = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;GA&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;Georgia&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(georgia.date, georgia.hospitalizedCurrently) plt.title(&#39;Number of Patients in GA Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values georgia[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] georgia.head() # Omit the NaN cols georgia = georgia[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots GA # Split dependent var from independent variables target_ga = georgia.hospitalizedCurrently indep_var_ga = georgia.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_ga.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_ga[col], y=target_ga, data=indep_var_ga, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables TX&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of GA fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(georgia.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=georgia[col], data=georgia, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables GA&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endgeorgia . Alabama: . bama = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;AL&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;Alabama&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(bama.date, bama.hospitalizedCurrently) plt.title(&#39;Number of Patients in AL Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values bama[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] bama.head() # Omit the NaN cols bama = bama[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots AL # Split dependent var from independent variables target_al = bama.hospitalizedCurrently indep_var_al = bama.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_al.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_al[col], y=target_al, data=indep_var_al, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables AL&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of AL fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(bama.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=bama[col], data=bama, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables TX&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endalabama . Oklahoma: . oklahoma = covid_df.loc[(covid_df[&#39;abbrev&#39;] == &#39;OK&#39;) &amp; (covid_df[&#39;state&#39;]== &#39;Oklahoma&#39;)] . # TODO fix legend/axis/plot alltogether # Timeseries plt fig, ax = plt.subplots(figsize = (16, 12)) plt.plot(oklahoma.date, oklahoma.hospitalizedCurrently) plt.title(&#39;Number of Patients in OK Currently Hospitalized&#39;) plt.xlabel(&#39;Date&#39;) plt.ylabel(&#39;No. Patients&#39;) . Text(0, 0.5, &#39;No. Patients&#39;) . # Checking which cols have NaN values oklahoma[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;, &#39;hospitalized&#39;]] oklahoma.head() # Omit the NaN cols oklahoma = oklahoma[[&#39;positive&#39;, &#39;active&#39;, &#39;hospitalizedCurrently&#39;, &#39;inIcuCurrently&#39;, &#39;recovered&#39;, &#39;death&#39;]] . # Scatter plots OK # Split dependent var from independent variables target_ok = oklahoma.hospitalizedCurrently indep_var_ok = oklahoma.drop(columns=[&#39;hospitalizedCurrently&#39;]) fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(indep_var_ok.columns): ax=fig.add_subplot(2, 3, i+1) sns.regplot(x=indep_var_ok[col], y=target_ok, data=indep_var_ok, label=col, scatter_kws={&#39;s&#39;:10}, line_kws={&quot;color&quot;: &quot;plum&quot;}) plt.suptitle(&#39;Distributions of Independent Variables OK&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . # Boxplot of OK fig, ax = plt.subplots(figsize = (16, 16)) for i, col in enumerate(oklahoma.columns): ax=fig.add_subplot(3, 3, i+1) sns.boxplot(x=oklahoma[col], data=oklahoma, color=&#39;lightpink&#39;, showfliers=True) plt.suptitle(&#39;Boxplots of Independent Variables OK&#39;, fontsize=18) plt.tight_layout() fig.subplots_adjust(top=0.95) . ###endoklahoma . Assessing Correlation of Independent Variables . # TODO add some explanation / look more into collinear variables . # Heatmap of correlations # Save correlations to variable corr = covid_cleaned.corr(method=&#39;pearson&#39;) # We can create a mask to not show duplicate values mask = np.triu(np.ones_like(corr, dtype=np.bool)) # Set up the matplotlib figure fig, ax = plt.subplots(figsize=(16,16)) # Generate heatmap sns.heatmap(corr, annot=True, mask=mask, cmap=&#39;GnBu&#39;, center=0, square=True, linewidths=.5, cbar_kws={&quot;shrink&quot;: .5}) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x1abdcb42b08&gt; . Step 3: Build model for dependent Variable . To be used to predict hospitalizedCurrently | Having more complete variables for inICUCurrently and onVentilatorCurrently will allow us to predict these numbers as well | . # We compare three models: # - Polynomial Regression # - Linear Regression # - ElasticNet # Copy DFs to not mess up original one # We will use model_df for our regression model model_df = all_cases.copy() # Delete redundant rows for row in [&#39;abbrev&#39;, &#39;bedsPerThousand&#39;, &#39;hospitalized&#39;, &#39;state&#39;, &#39;hospitalizedCumulative&#39;, &#39;dataQualityGrade&#39;, &#39;lastUpdateEt&#39;]: del model_df[row] # Drop NaN values for hospitalizedCurrently model_df = model_df.dropna(subset=[&#39;hospitalizedCurrently&#39;]) # Drop Values with abnormal active-hospitalised ratios (outside Conf. Interval) model_df[&#39;ratio_hospital&#39;] = model_df[&#39;hospitalizedCurrently&#39;] / model_df[&#39;active&#39;] model_df = model_df[~(model_df[&#39;ratio_hospital&#39;] &gt;= model_df.ratio_hospital.quantile(0.99))] #model_df = model_df[~(model_df[&#39;ratio_hospital&#39;] &lt;= model_df[&#39;ratio_hospital&#39;].median())] del model_df[&#39;ratio_hospital&#39;] # Get peek of model to use model_df.describe() . population positive active hospitalizedCurrently inIcuCurrently onVentilatorCurrently recovered death totalTestsViral positiveTestsViral negativeTestsViral positiveCasesViral commercialScore negativeRegularScore negativeScore positiveScore score grade total_beds . count 3515.000 | 3515.000 | 3515.000 | 3515.000 | 1784.000 | 1583.000 | 3515.000 | 3515.000 | 1079.000 | 383.000 | 382.000 | 2441.000 | 3515.000 | 3515.000 | 3515.000 | 3515.000 | 3515.000 | 0.000 | 3515.000 | . mean 6742215.381 | 31355.048 | 27858.963 | 1029.290 | 444.145 | 225.527 | 6809.578 | 1696.697 | 388488.307 | 24974.708 | 235269.796 | 36143.066 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 16019.574 | . std 7749524.762 | 56347.216 | 50875.985 | 1946.232 | 704.719 | 334.798 | 13206.737 | 3575.315 | 523078.795 | 25922.592 | 225340.603 | 60974.372 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 16533.007 | . min 567025.000 | 115.000 | 113.000 | 1.000 | 2.000 | 0.000 | 0.000 | 0.000 | 9055.000 | 407.000 | 8648.000 | 396.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 1318.928 | . 25% 1778070.000 | 3203.000 | 2818.000 | 117.500 | 81.000 | 34.500 | 0.000 | 88.000 | 85635.000 | 4128.000 | 62359.250 | 6344.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 3773.952 | . 50% 4645184.000 | 11948.000 | 10014.000 | 402.000 | 181.000 | 92.000 | 1252.000 | 466.000 | 213753.000 | 13853.000 | 167221.500 | 16083.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 11557.920 | . 75% 8626207.000 | 34570.000 | 29929.500 | 1033.500 | 476.750 | 244.000 | 6102.000 | 1579.000 | 472451.000 | 43427.000 | 286083.250 | 40022.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 19124.737 | . max 39937489.000 | 391220.000 | 356899.000 | 18825.000 | 5225.000 | 2425.000 | 76282.000 | 24814.000 | 3771314.000 | 86113.000 | 912377.000 | 391220.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | nan | 71887.480 | . ### Mark Bee (https://www.facebook.com/markbeenyc) - do you need a sippy cup lesson on this information? .",
            "url": "https://bielsnor.github.io/futureproof/futureproof-COVID19-us-hosp/",
            "relUrl": "/futureproof-COVID19-us-hosp/",
            "date": " • Jun 26, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "COVID-19-Growth By State (US)",
            "content": ". Warning: The number of cases data can be heavily biased depending on a state&#8217;s testing procedures and how widely the population is tested. Read with caution. . #Click on each state to see data . ###data sourced from JHU, WHO, Varaious US Federal Agencies .",
            "url": "https://bielsnor.github.io/futureproof/futureproof-6COVID19-USA/",
            "relUrl": "/futureproof-6COVID19-USA/",
            "date": " • Jun 4, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Title",
            "content": "# Compare Death Rate Trajectories &gt; Comparing different countries&#39; death rate trajectories with those of Italy, South Korea, Japan and Lombardy, as well as US states. - comments: false - toc: true - categories: [growth, compare, death, interactive] - image: images/covid-compare-country-death-trajectories.png - permalink: /futureproof-COVID19-girls-v-trump/ How do female led countries compare to the United States with regard to COVID19 death rate trajectory? . Click (Shift+ for multiple) on Countries legend to filter the visualization. . Last Updated on April, 22 2020",
            "url": "https://bielsnor.github.io/futureproof/2020/04/17/death-traj_females_v_trump.html",
            "relUrl": "/2020/04/17/death-traj_females_v_trump.html",
            "date": " • Apr 17, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "COVID-19-Growth By State (US)",
            "content": ". Tip: Click (Shift+ for multiple) on states in the legend to filter the visualizations below. Click outside the legend to highlight all states. . Total Cases . . Warning: The number of cases per capita can be heavily biased depending on a state&#8217;s testing procedures and how widely the population is tested. Read with caution. . Total Deaths . ###Click on each state to see data .",
            "url": "https://bielsnor.github.io/futureproof/futureproof-COVID19-USA/",
            "relUrl": "/futureproof-COVID19-USA/",
            "date": " • Apr 17, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "How many cases of COVID-19 does each U.S. state really have?",
            "content": ". Note: This dashboard contains the results of a predictive model. The author has tried to make it as accurate as possible. But the COVID-19 situation is changing quickly, and these models inevitably include some level of speculation. . COVID-19 Case Estimates, by State . Definition Of Fields: . Reported Cases: The number of cases reported by each state, which is a function of how many tests are positive. | Est Cases: The predicted number of cases, accounting for the fact that not everyone is tested. | Est Range: The 95% confidence interval of the predicted number of cases. | Ratio: Estimated Cases divided by Reported Cases. | Tests per Million: The number of tests administered per one million people. The less tests administered per capita, the larger the difference between reported and estimated number of cases, generally. | Cases per Million: The number of reported cases per on million people. | Positive Test Rate: The reported percentage of positive tests. | . Appendix: Model Diagnostics . Derived relationship between Test Capacity and Case Under-reporting . Plotted is the estimated relationship between test capacity (in terms of people per test -- larger = less testing) and the likelihood a COVID-19 case is reported (lower = more under-reporting of cases). . The lines represent the posterior samples from our MCMC run (note the x-axis is plotted on a log scale). The rug plot shows the current test capacity for each state (black &#39;|&#39;) and the capacity one week ago (cyan &#39;+&#39;). For comparison, South Korea&#39;s testing capacity is currently at the very left of the graph (200 people per test). . About this Analysis . This analysis was done by Joseph Richards. . This project1 uses the testing rates per state from https://covidtracking.com/, which reports case counts and mortality by state. This is used to estimate the number of unreported (untested) COVID-19 cases in each U.S. state. . The analysis makes a few assumptions: . The probability that a case is reported by a state is a function of the number of tests run per person in that state. Hence the degree of under-reported cases is a function of tests run per capita. | The underlying mortality rate is the same across every state. | Patients take time to succumb to COVID-19, so the mortality counts today reflect the case counts 7 days ago. E.g., mortality rate = (cumulative deaths today) / (cumulative cases 7 days ago). | The model attempts to find the most likely relationship between state-wise test volume (per capita) and under-reporting, such that the true underlying mortality rates between the individual states are as similar as possible. The model simultaneously finds the most likely posterior distribution of mortality rates, the most likely true case count per state, and the test volume vs. case underreporting relationship. . . Full details about the model are available at: https://github.com/jwrichar/COVID19-mortality&#8617; . |",
            "url": "https://bielsnor.github.io/futureproof/covid-19-us-case-estimation/",
            "relUrl": "/covid-19-us-case-estimation/",
            "date": " • Mar 31, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Estimating The Infected Population From Deaths",
            "content": ". Note: This dashboard contains the results of a predictive model. The author has tried to make it as accurate as possible. But the COVID-19 situation is changing quickly, and these models inevitably include some level of speculation. . Estimated Infected Population By Country . with respect to days since outbreak . Tip: Click (Shift+ for multiple) on countries in the legend to filter the visualization. . FileNotFoundError Traceback (most recent call last) C: ProgramData Anaconda3 lib site-packages selenium webdriver common service.py in start(self) 75 stderr=self.log_file, &gt; 76 stdin=PIPE) 77 except TypeError: C: ProgramData Anaconda3 lib subprocess.py in __init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text) 799 errread, errwrite, --&gt; 800 restore_signals, start_new_session) 801 except: C: ProgramData Anaconda3 lib subprocess.py in _execute_child(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session) 1206 os.fspath(cwd) if cwd is not None else None, -&gt; 1207 startupinfo) 1208 finally: FileNotFoundError: [WinError 2] The system cannot find the file specified During handling of the above exception, another exception occurred: WebDriverException Traceback (most recent call last) &lt;ipython-input-4-13d297b27ddd&gt; in &lt;module&gt; 2 # Plot estimated absolute number of infected 3 plot1 = plot(data_countries_pc, &#34;line&#34;, True) -&gt; 4 plot1.save(&#34;../images/covid-estimate-infections.png&#34;) 5 plot1 C: ProgramData Anaconda3 lib site-packages altair vegalite v4 api.py in save(self, fp, format, override_data_transformer, scale_factor, vegalite_version, vega_version, vegaembed_version, **kwargs) 445 if override_data_transformer: 446 with data_transformers.disable_max_rows(): --&gt; 447 result = save(**kwds) 448 else: 449 result = save(**kwds) C: ProgramData Anaconda3 lib site-packages altair utils save.py in save(chart, fp, vega_version, vegaembed_version, format, mode, vegalite_version, embed_options, json_kwds, webdriver, scale_factor, **kwargs) 100 vegaembed_version=vegaembed_version, 101 webdriver=webdriver, --&gt; 102 scale_factor=scale_factor, **kwargs) 103 if format == &#39;png&#39;: 104 write_file_or_filename(fp, mimebundle[&#39;image/png&#39;], mode=&#39;wb&#39;) C: ProgramData Anaconda3 lib site-packages altair utils mimebundle.py in spec_to_mimebundle(spec, format, mode, vega_version, vegaembed_version, vegalite_version, **kwargs) 54 vega_version=vega_version, 55 vegaembed_version=vegaembed_version, &gt; 56 vegalite_version=vegalite_version, **kwargs) 57 if format == &#39;png&#39;: 58 render = base64.b64decode(render.split(&#39;,&#39;, 1)[1].encode()) C: ProgramData Anaconda3 lib site-packages altair utils headless.py in compile_spec(spec, format, mode, vega_version, vegaembed_version, vegalite_version, scale_factor, driver_timeout, webdriver) 155 webdriver_options.add_argument(&#39;--no-sandbox&#39;) 156 --&gt; 157 driver = webdriver_class(options=webdriver_options) 158 159 try: C: ProgramData Anaconda3 lib site-packages selenium webdriver chrome webdriver.py in __init__(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive) 71 service_args=service_args, 72 log_path=service_log_path) &gt; 73 self.service.start() 74 75 try: C: ProgramData Anaconda3 lib site-packages selenium webdriver common service.py in start(self) 81 raise WebDriverException( 82 &#34;&#39;%s&#39; executable needs to be in PATH. %s&#34; % ( &gt; 83 os.path.basename(self.path), self.start_error_message) 84 ) 85 elif err.errno == errno.EACCES: WebDriverException: Message: &#39;chromedriver&#39; executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home . Latest Country Estimates . Infected vs. number of confirmed cases . Allows you to compare how countries have been tracking the true number of infected people. The smaller deviation from the dashed line (45 degree line) the better job at tracking the true number of infected people. . . Tip: Click (Shift+ for multiple) on countries in the legend to filter the visualization. . Latest Observed vs. Estimate of Infected Cases . Methodology . We argue that the number of infected in the past can be inferred using today&#39;s number of deaths and average fatality rate from confirmed cases in the following way: . $$I_{t-j} = frac{D_t}{{CFR}_t}$$ . where $I_t$ = number of infected, $D_t$ = number of deaths, and ${CFR}_t $ = case fatality rate = $ frac{D}{C}$. The $j$ depends on the average number of days that covid patients die after having the first symptoms. . Assumption 1: The case fatality rate is a good proxy for the fatality rate of the infected population . Then, in order to estimate the current number of infected $I_t$ we need to estimate its growth rate from $t-j$ to $t$. . $$I_t = (1+ hat{g})^j I_{t-j}$$ . Assumption 2: The growth rate of infected $ hat{g}$ is an unbiased estimate of $g$ . . For now we estimate $g$ using the average growth rate since having the first infected person. . Assumption 3: It takes on average 8 days to die after having the first symptoms. . This analysis was conducted by Joao B. Duarte. Relevant sources are listed below: . 2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE GitHub repository. . | Feenstra, Robert C., Robert Inklaar and Marcel P. Timmer (2015), &quot;The Next Generation of the Penn World Table&quot; American Economic Review, 105(10), 3150-3182 . |",
            "url": "https://bielsnor.github.io/futureproof/covid-infected/",
            "relUrl": "/covid-infected/",
            "date": " • Mar 30, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "COVID-19 Growth Rate Prediction",
            "content": ". Note: This dashboard contains the results of a predictive model. The model is assuming an exponential growth rate in the initial stages of the COVID19 pandemic. Data is changing hourly therefore the accuracy of the model is variable. This is for informational purposes only. . Predicted Cases By Country . Select a country from the drop down list below to toggle the visualization. . Growth Rate Predictions . Text(0.5, 0.98, &#39;Posterior of daily growth&#39;) . Model Diagnostics - Trace Plots . The following trace plots help to assess the convergence of the MCMC sampler. You can safely ignore this if not familiar with MCMC. . Analysis Overview . The model that we are building assumes exponential growth. This is only applicable to the initial stages of a pandemic outbreak once growth slows the accuracy of the model will deteriorate to statistical insignificance. However, in the early stages of an outbreak it can provide an accurate scale and trajectory.1 . We assume a negative binomial likelihood as we are dealing with count data. A Poisson could also be used but the negative binomial allows us to also model the variance separately to give more flexibility. . The model is also hierarchical, pooling information from individual countries. . . This notebook gets up-to-date data from the &quot;2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE&quot; GitHub repository. This code is provided under the BSD-3 License.&#8617; . |",
            "url": "https://bielsnor.github.io/futureproof/growth-bayes/",
            "relUrl": "/growth-bayes/",
            "date": " • Mar 30, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "COVID-19 Deaths Per Capita",
            "content": "Deaths Per Million Of Inhabitants . Since reaching at least 1 death per million . Tip: Click (Shift+ for multiple) on countries in the legend to filter the visualization. . Last Available Total Deaths By Country: . Appendix . . Warning: The following chart, &quot;Cases Per Million of Habitants&quot; is biased depending on how widely a country administers tests. Please read with caution. . Cases Per Million of Habitants . Last Available Cases Per Million By Country: . Data Source: &quot;2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE&quot; GitHub repository. . Research: Feenstra, Robert C., Robert Inklaar and Marcel P. Timmer (2015), &quot;The Next Generation of the Penn World Table&quot; American Economic Review, 105(10), 3150-3182 .",
            "url": "https://bielsnor.github.io/futureproof/futureproof-COVID19-covid-compare-permillion/",
            "relUrl": "/futureproof-COVID19-covid-compare-permillion/",
            "date": " • Mar 28, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Compare Death Rate Trajectories",
            "content": "Comparing Death Trajectory by Country . Where does your country stand today compared to Lombardy? . Click (Shift+ for multiple) on Countries legend to filter the visualization. . Last Updated on April, 15 2020 Select a country from the drop down list below to toggle the visualization. . A Lesson from Lombardy We Must Head . Lombardy, a small region of Italy with a population of only 10 million people has experienced an extremely high death rate. This shows that the virus has a high mortality rate even on a small demographic scale, likely due to overwhelmed healthcare services. . Where does your country stand in comparison to Lombardy? . Click (Shift+ for multiple) on Countries legend to filter the visualization. .",
            "url": "https://bielsnor.github.io/futureproof/futureproof-COVID19-compare-country-death-trajectories/",
            "relUrl": "/futureproof-COVID19-compare-country-death-trajectories/",
            "date": " • Mar 27, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "COVID-19-Growth By State (US)",
            "content": ". Tip: Click (Shift+ for multiple) on states in the legend to filter the visualizations below. Click outside the legend to highlight all states. . Total Cases . . Warning: The number of cases per capita can be heavily biased depending on a state&#8217;s testing procedures and how widely the population is tested. Read with caution. . Total Deaths . ###Click on each state to see data .",
            "url": "https://bielsnor.github.io/futureproof/futureproof-COVID19-USA/",
            "relUrl": "/futureproof-COVID19-USA/",
            "date": " • Mar 27, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "COVID-19 Growth Rate Prediction",
            "content": ". Note: This dashboard contains the results of a predictive model. This analysis is provided for informational purposes only. . Data . These are the countries included in the model: . &#34;Afghanistan, Albania, Algeria, Andorra, Argentina, Armenia, Australia (total), Austria, Azerbaijan, Bahrain, Belarus, Belgium, Bosnia and Herzegovina, Brazil, Brunei, Bulgaria, Burkina Faso, Cambodia, Cameroon, Canada (total), Chile, Colombia, Costa Rica, Cote d&#39;Ivoire, Croatia, Cuba, Cyprus, Czechia, Denmark, Denmark (total), Diamond Princess, Dominican Republic, Ecuador, Egypt, Estonia, Finland, France, France (total), Georgia, Germany, Ghana, Greece, Honduras, Hong Kong, Hungary, Iceland, India, Indonesia, Iran, Iraq, Ireland, Israel, Italy, Japan, Jordan, Kazakhstan, Korea, South, Kuwait, Latvia, Lebanon, Lithuania, Luxembourg, Malaysia, Malta, Mauritius, Mexico, Moldova, Morocco, Netherlands, New Zealand, Nigeria, North Macedonia, Norway, Oman, Pakistan, Panama, Peru, Philippines, Poland, Portugal, Qatar, Romania, Russia, San Marino, Saudi Arabia, Senegal, Serbia, Singapore, Slovakia, Slovenia, South Africa, Spain, Sri Lanka, Sweden, Switzerland, Taiwan*, Thailand, Tunisia, Turkey, US, Ukraine, United Arab Emirates, United Kingdom, United Kingdom (total), Uruguay, Uzbekistan, Venezuela, Vietnam, West Bank and Gaza&#34; . Predicted Cases By Country . Select a country from the drop down list below to toggle the visualization. . Growth Rate Predictions . Text(0.5, 0.98, &#39;Posterior of daily growth&#39;) . Model Diagnostics - Trace Plots . The following trace plots help to assess the convergence of the MCMC sampler. You can safely ignore this if not familiar with MCMC. . About This Analysis . The model that we are building assumes exponential growth. This is definitely wrong because growth would just continue uninterrupted into the future. However, in the early phase of an epidemic it&#39;s a reasonable assumption.1 . We assume a negative binomial likelihood as we are dealing with count data. A Poisson could also be used but the negative binomial allows us to also model the variance separately to give more flexibility. . The model is also hierarchical, pooling information from individual countries. . . This notebook gets up-to-date data from the &quot;2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE&quot; GitHub repository. This code is provided under the BSD-3 License. Link to original notebook.&#8617; . |",
            "url": "https://bielsnor.github.io/futureproof/growth-bayes/",
            "relUrl": "/growth-bayes/",
            "date": " • Mar 16, 2020"
        }
        
    
  

  
  

  

  
  

  
  

  
  

  
  

}